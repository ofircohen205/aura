# Aura Environment Configuration Example
# Copy this file to .env.local, .env.staging, or .env.production
# Set ENVIRONMENT variable to select which config file to use

# ============================================================================
# Environment
# ============================================================================
# Set to: local, staging, or production
ENVIRONMENT=local

# ============================================================================
# Database Configuration
# ============================================================================
# PostgreSQL connection string for LangGraph checkpointer
# WARNING: Change default credentials in production!
POSTGRES_DB_URI=postgresql+psycopg://aura:aura@localhost:5432/aura_db
POSTGRES_POOL_MAX_SIZE=20
POSTGRES_POOL_MIN_SIZE=5

# ============================================================================
# CORS Configuration
# ============================================================================
# Allowed CORS origins (comma-separated or "*" for all in local only)
# WARNING: "*" is only allowed in local environment
CORS_ALLOW_ORIGINS=["*"]
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=["*"]
CORS_ALLOW_HEADERS=["*"]

# ============================================================================
# API Configuration
# ============================================================================
API_TITLE=Aura Backend
API_VERSION=0.1.0

# ============================================================================
# Logging Configuration
# ============================================================================
# Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
# Log format: json (production) or text (local development)
LOG_FORMAT=text

# ============================================================================
# ============================================================================
# Rate Limiting Configuration
# ============================================================================
# NOTE: Requires Redis for distributed rate limiting (works across multiple instances)
# Set RATE_LIMIT_REDIS_ENABLED=false to disable Redis (rate limiting will be disabled)
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REDIS_ENABLED=true
RATE_LIMIT_REDIS_URL=redis://localhost:6379/1
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60
# ============================================================================
# For production, implement Redis-based rate limiting
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REDIS_ENABLED=true
RATE_LIMIT_REDIS_URL=redis://localhost:6379/1
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60

# ============================================================================
# LLM Configuration
# ============================================================================
# Enable/disable LLM features
LLM_ENABLED=true
# OpenAI model to use
LLM_MODEL=gpt-4o-mini
# Temperature for LLM responses (0.0-2.0)
LLM_TEMPERATURE=0.7
# Maximum retries for LLM calls
LLM_MAX_RETRIES=3
# Retry backoff factor (exponential backoff)
LLM_RETRY_BACKOFF_FACTOR=2.0
# Initial retry delay in seconds
LLM_INITIAL_RETRY_DELAY=1.0
# LLM request timeout in seconds
LLM_TIMEOUT=60

# OpenAI API Key (required if LLM_ENABLED=true)
# OPENAI_API_KEY=your-api-key-here

# ============================================================================
# Embedding Configuration
# ============================================================================
# Embedding model to use
EMBEDDING_MODEL=text-embedding-3-small
# Embedding provider: openai or local
EMBEDDING_PROVIDER=openai

# ============================================================================
# RAG (Retrieval-Augmented Generation) Configuration
# ============================================================================
# Enable/disable RAG service
RAG_ENABLED=true
# Number of documents to retrieve
RAG_TOP_K=3
# Similarity threshold for retrieval
RAG_SIMILARITY_THRESHOLD=0.7

# ============================================================================
# Vector Store Configuration
# ============================================================================
# Vector store type (pgvector only - PostgreSQL extension for vector similarity search)
VECTOR_STORE_TYPE=pgvector

# pgvector Configuration (PostgreSQL extension)
# Connection string for pgvector (can use DATABASE_URL as fallback)
PGVECTOR_CONNECTION_STRING=postgresql://user:password@localhost:5432/aura
# Collection/namespace name
PGVECTOR_COLLECTION=aura_knowledge_base
# Table name for embeddings
PGVECTOR_TABLE_NAME=embeddings

# ============================================================================
# Chunking Strategy Configuration
# ============================================================================
# Chunking strategy: fixed, recursive, or semantic
CHUNKING_STRATEGY=recursive
# Chunk size in characters
CHUNK_SIZE=1000
# Chunk overlap in characters
CHUNK_OVERLAP=200

# ============================================================================
# Evaluation Configuration
# ============================================================================
# Enable/disable evaluation features
EVAL_ENABLED=false
# Path to evaluation dataset
EVAL_DATASET_PATH=./eval_dataset.json

# ============================================================================
# Struggle Detection Configuration
# ============================================================================
# Threshold for edit frequency (edits per time unit)
STRUGGLE_THRESHOLD_EDIT_FREQUENCY=10.0
# Threshold for error count
STRUGGLE_THRESHOLD_ERROR_COUNT=2

# ============================================================================
# Code Audit Configuration
# ============================================================================
# Maximum function length before flagging (in lines)
AUDIT_FUNCTION_LENGTH_THRESHOLD=50

# ============================================================================
# LLM Caching Configuration
# ============================================================================
# Enable/disable LLM response caching
LLM_CACHE_ENABLED=true
# Cache TTL in seconds (1 hour default)
LLM_CACHE_TTL=3600
# Maximum cache size (for in-memory fallback)
LLM_CACHE_MAX_SIZE=1000

# ============================================================================
# Redis Configuration (for distributed caching and rate limiting)
# ============================================================================
# Enable/disable Redis
REDIS_ENABLED=false
# Redis connection URL
REDIS_URL=redis://localhost:6379/0
# Key prefix for Redis keys
REDIS_KEY_PREFIX=aura:llm:cache:
# Connection pool size
REDIS_CONNECTION_POOL_SIZE=10
# Socket timeout in seconds
REDIS_SOCKET_TIMEOUT=5.0
# Socket connect timeout in seconds
REDIS_SOCKET_CONNECT_TIMEOUT=5.0

# ============================================================================
# LLM Batching Configuration
# ============================================================================
# Number of prompts per batch
LLM_BATCH_SIZE=5
# Delay between batches in seconds
LLM_BATCH_DELAY=0.1

# ============================================================================
# Notes
# ============================================================================
# 1. For production, ensure all secrets are set via environment variables
#    or a secure secret management system (not in .env files)
# 2. Default database credentials are for local development only
# 3. Rate limiting currently uses in-memory storage - not suitable for
#    distributed systems. Use Redis-based rate limiting in production.
# 4. SHA256 password hashing is NOT production-ready. Use bcrypt or argon2.
# 5. JWT functions are placeholders - implement proper JWT handling for auth.
