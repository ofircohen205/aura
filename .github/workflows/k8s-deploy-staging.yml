name: Deploy to Staging

on:
  # Auto-deploy after images are built on main branch
  workflow_run:
    workflows: ["Build and Push Docker Images"]
    types:
      - completed
    branches: [main]
  # Deploy on k8s manifest changes
  push:
    branches: [main]
    paths:
      - "k8s/**"
      - ".github/workflows/k8s-deploy-staging.yml"
  # Manual deployment
  workflow_dispatch:
    inputs:
      image_tag:
        description: "Image tag to deploy (default: git SHA or 'staging')"
        required: false
        type: string
        default: ""

env:
  KUBERNETES_NAMESPACE: aura-staging
  REGISTRY: ghcr.io
  IMAGE_PREFIX: ${{ github.repository_owner }}

jobs:
  deploy:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    # Only deploy if triggered by workflow_run and the build succeeded
    if: |
      (github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'success') ||
       github.event_name == 'push' ||
       github.event_name == 'workflow_dispatch')
    environment:
      name: staging
      url: https://app.staging.aura.example.com

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        # For workflow_run, checkout the commit that triggered the build
        with:
          ref: ${{ github.event.workflow_run.head_branch || github.ref }}
          sha: ${{ github.event.workflow_run.head_sha || github.sha }}

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: "latest"

      - name: Set up kustomize
        uses: imranismail/setup-kustomize@v2
        with:
          kustomize-version: "5.3.0"

      - name: Configure kubectl
        run: |
          mkdir -p $HOME/.kube

          # Check if secret is set
          if [ -z "${{ secrets.KUBECONFIG_STAGING }}" ]; then
            echo "Error: KUBECONFIG_STAGING secret is not set"
            exit 1
          fi

          # Decode and write kubeconfig
          echo "${{ secrets.KUBECONFIG_STAGING }}" | base64 -d > $HOME/.kube/config

          # Verify kubeconfig file was created and has content
          if [ ! -s "$HOME/.kube/config" ]; then
            echo "Error: kubeconfig file is empty or was not created"
            exit 1
          fi

          # Verify kubeconfig is valid YAML/JSON
          if ! kubectl config view &> /dev/null; then
            echo "Error: Invalid kubeconfig format"
            kubectl config view 2>&1 | head -20
            exit 1
          fi

          # Get list of contexts
          CONTEXTS=$(kubectl config get-contexts -o name 2>/dev/null || echo "")
          if [ -z "$CONTEXTS" ]; then
            echo "Error: No contexts found in kubeconfig"
            echo "Kubeconfig contents:"
            cat $HOME/.kube/config | head -20
            exit 1
          fi

          # Get current context or use the first available context
          CURRENT_CONTEXT=$(kubectl config current-context 2>/dev/null || echo "")
          if [ -z "$CURRENT_CONTEXT" ]; then
            CURRENT_CONTEXT=$(echo "$CONTEXTS" | head -1)
            echo "No current context set, using first available: $CURRENT_CONTEXT"
          fi

          # Set the namespace for the context
          kubectl config set-context "$CURRENT_CONTEXT" --namespace=${{ env.KUBERNETES_NAMESPACE }}
          kubectl config use-context "$CURRENT_CONTEXT"

          # Verify context is set
          kubectl config current-context

          # Validate that the server URL is not localhost (won't work in CI)
          SERVER_URL=$(kubectl config view --minify -o jsonpath='{.clusters[0].cluster.server}' 2>/dev/null || echo "")
          if [ -z "$SERVER_URL" ]; then
            echo "::error::Could not extract server URL from kubeconfig"
            exit 1
          fi

          echo "Cluster server URL: $SERVER_URL"

          # Check if server is localhost (won't work in CI)
          if echo "$SERVER_URL" | grep -qE "^(https?://)?(127\.0\.0\.1|localhost|::1)"; then
            echo "::error::Kubeconfig points to localhost, which won't work in CI/CD"
            echo ""
            echo "The kubeconfig server URL is: $SERVER_URL"
            echo ""
            echo "This appears to be a local Kubernetes cluster (minikube, kind, etc.) or a port-forward."
            echo "For CI/CD deployments, you need a kubeconfig for a remote/cloud Kubernetes cluster."
            echo ""
            echo "See docs/GITHUB_SECRETS.md for instructions on getting a remote cluster kubeconfig."
            exit 1
          fi

      - name: Verify cluster connection
        run: |
          echo "Verifying connection to cluster..."
          if ! kubectl cluster-info &> /tmp/cluster-info.log; then
            echo "::error::Failed to connect to Kubernetes cluster"
            echo ""
            echo "Cluster connection failed. See docs/GITHUB_SECRETS.md for troubleshooting."
            echo ""
            echo "Server URL: $(kubectl config view --minify -o jsonpath='{.clusters[0].cluster.server}' 2>/dev/null || echo 'unknown')"
            echo ""
            echo "Error details:"
            cat /tmp/cluster-info.log
            exit 1
          fi
          echo "âœ“ Successfully connected to cluster"

      - name: Determine image tag
        id: image-tag
        run: |
          # Priority: manual input > workflow_run SHA > push SHA > default
          if [ -n "${{ inputs.image_tag }}" ]; then
            echo "tag=${{ inputs.image_tag }}" >> $GITHUB_OUTPUT
          elif [ "${{ github.event_name }}" == "workflow_run" ]; then
            # Use the commit SHA from the build workflow
            echo "tag=${{ github.event.workflow_run.head_sha }}" >> $GITHUB_OUTPUT
          elif [ "${{ github.event_name }}" == "push" ]; then
            # Use current commit SHA
            echo "tag=${{ github.sha }}" >> $GITHUB_OUTPUT
          else
            # Default to 'staging' tag
            echo "tag=staging" >> $GITHUB_OUTPUT
          fi
          echo "Using image tag: $(cat $GITHUB_OUTPUT | grep '^tag=' | cut -d'=' -f2)"

      - name: Update image tags in kustomization
        run: |
          IMAGE_TAG="${{ steps.image-tag.outputs.tag }}"
          cd k8s/overlays/staging
          kustomize edit set image \
            aura-backend=${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/aura-backend:$IMAGE_TAG \
            aura-web-dashboard=${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/aura-web-dashboard:$IMAGE_TAG

      - name: Deploy to Kubernetes
        run: |
          kubectl apply -k k8s/overlays/staging
          kubectl rollout status deployment/backend -n ${{ env.KUBERNETES_NAMESPACE }} --timeout=10m
          kubectl rollout status deployment/web-dashboard -n ${{ env.KUBERNETES_NAMESPACE }} --timeout=10m

      - name: Verify deployment
        run: |
          kubectl get pods -n ${{ env.KUBERNETES_NAMESPACE }}
          kubectl get svc -n ${{ env.KUBERNETES_NAMESPACE }}
          kubectl get ingress -n ${{ env.KUBERNETES_NAMESPACE }}

      - name: Run health checks
        run: |
          # Wait for services to be ready after deployment
          sleep 30
          # Run comprehensive health checks
          chmod +x k8s/scripts/health-check.sh
          ./k8s/scripts/health-check.sh staging ${{ env.KUBERNETES_NAMESPACE }} 30 5
